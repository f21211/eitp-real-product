#!/usr/bin/env python3
"""
CEPç†è®ºç®€å•éªŒè¯æµ‹è¯•
å¿«é€ŸéªŒè¯CEPç†è®ºçš„æ ¸å¿ƒé¢„æµ‹
"""

import torch
import torch.nn as nn
import numpy as np
import time
import json
from datetime import datetime

print("=" * 80)
print("ğŸ”¬ CEPç†è®ºç®€å•éªŒè¯æµ‹è¯•")
print("=" * 80)
print()

# åŠ è½½æ„è¯†æ£€æµ‹å·¥å…·
try:
    from consciousness_detection_tool import ConsciousnessDetector
    print("âœ… æˆåŠŸå¯¼å…¥æ„è¯†æ£€æµ‹å·¥å…·")
    has_detector = True
except ImportError:
    print("âš ï¸  æ„è¯†æ£€æµ‹å·¥å…·æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    has_detector = False

print()

# ============================================================================
# éªŒè¯1: å¤æ‚åº¦ä¸æ™ºèƒ½æ°´å¹³çš„å…³ç³»
# ============================================================================

print("=" * 80)
print("éªŒè¯1: å¤æ‚åº¦é˜ˆå€¼æµ‹è¯•")
print("=" * 80)
print("CEPé¢„æµ‹: åªæœ‰è¾¾åˆ°ç‰¹å®šå¤æ‚åº¦ï¼ˆDâ‰¥2.7, Î»â‰¥0.8ï¼‰æ‰èƒ½äº§ç”Ÿæ¶Œç°æ™ºèƒ½")
print()

def calculate_fractal_dimension(tensor):
    """ç®€åŒ–çš„åˆ†å½¢ç»´åº¦è®¡ç®—"""
    if tensor.numel() == 0:
        return 1.0
    
    # ä½¿ç”¨box-countingæ–¹æ³•çš„ç®€åŒ–ç‰ˆæœ¬
    flat = tensor.view(-1).cpu().numpy()
    # è®¡ç®—ä¸åŒå°ºåº¦ä¸‹çš„"ç›’å­"æ•°é‡
    scales = [1, 2, 4, 8, 16]
    counts = []
    
    for scale in scales:
        # ç²—ç²’åŒ–
        if len(flat) >= scale:
            coarse = flat[:len(flat)//scale*scale].reshape(-1, scale).mean(axis=1)
            # è®¡ç®—å”¯ä¸€å€¼çš„æ•°é‡ï¼ˆè¿‘ä¼¼ï¼‰
            unique_count = len(np.unique(np.round(coarse, 2)))
            counts.append(unique_count)
    
    if len(counts) < 2:
        return 2.0
    
    # å¯¹æ•°æ‹Ÿåˆ
    log_counts = np.log(counts[:len(scales)])
    log_scales = np.log(scales[:len(counts)])
    
    # è®¡ç®—æ–œç‡ï¼ˆåˆ†å½¢ç»´åº¦ï¼‰
    if len(log_scales) > 1:
        D = np.polyfit(log_scales, log_counts, 1)[0]
        return abs(D)
    return 2.0

def calculate_complexity_coefficient(model):
    """è®¡ç®—å¤æ‚åº¦ç³»æ•°Î»"""
    total_params = 0
    active_params = 0
    
    for param in model.parameters():
        total_params += param.numel()
        # æ´»è·ƒå‚æ•°ï¼ˆç»å¯¹å€¼å¤§äºé˜ˆå€¼ï¼‰
        active_params += (param.abs() > 1e-3).sum().item()
    
    if total_params == 0:
        return 0.0
    
    return active_params / total_params

def test_emergence_ability(model, test_data):
    """æµ‹è¯•æ¶Œç°èƒ½åŠ›ï¼ˆæ³›åŒ–èƒ½åŠ›ä½œä¸ºä»£ç†ï¼‰"""
    model.eval()
    with torch.no_grad():
        outputs = model(test_data)
        # è®¡ç®—è¾“å‡ºçš„å¤šæ ·æ€§å’Œç»“æ„æ€§
        diversity = outputs.std().item()
        structure = outputs.mean().item()
        emergence_score = diversity * abs(structure)
    return emergence_score

# åˆ›å»ºä¸åŒå¤æ‚åº¦çš„æ¨¡å‹
print("åˆ›å»ºä¸åŒå¤æ‚åº¦çš„æµ‹è¯•æ¨¡å‹...")
print()

class SimpleModel(nn.Module):
    def __init__(self, layers, dim):
        super().__init__()
        self.layers = nn.ModuleList([
            nn.Linear(dim, dim) for _ in range(layers)
        ])
        self.activation = nn.ReLU()
        
    def forward(self, x):
        for layer in self.layers:
            x = self.activation(layer(x))
        return x

# æµ‹è¯•ä¸åŒå¤æ‚åº¦
test_configs = [
    ('ä½å¤æ‚åº¦', 2, 32),   # é¢„æœŸ D~2.0, Î»~0.3
    ('ä¸­ä½å¤æ‚åº¦', 3, 64),  # é¢„æœŸ D~2.3, Î»~0.5
    ('ä¸­ç­‰å¤æ‚åº¦', 4, 128), # é¢„æœŸ D~2.5, Î»~0.6
    ('ä¸­é«˜å¤æ‚åº¦', 6, 192), # é¢„æœŸ D~2.7, Î»~0.7
    ('é«˜å¤æ‚åº¦', 8, 256),   # é¢„æœŸ D~2.9, Î»~0.8
]

results_validation1 = []

for name, layers, dim in test_configs:
    print(f"æµ‹è¯• {name} (layers={layers}, dim={dim})...")
    
    # åˆ›å»ºæ¨¡å‹
    model = SimpleModel(layers, dim)
    
    # éšæœºåˆå§‹åŒ–åè®¡ç®—å‚æ•°
    test_input = torch.randn(16, dim)
    
    # è®¡ç®—CEPå‚æ•°
    with torch.no_grad():
        output = model(test_input)
        D = calculate_fractal_dimension(output)
        lambda_val = calculate_complexity_coefficient(model)
    
    # æµ‹è¯•æ¶Œç°èƒ½åŠ›
    emergence = test_emergence_ability(model, test_input)
    
    result = {
        'name': name,
        'layers': layers,
        'dim': dim,
        'fractal_dimension': float(D),
        'complexity_coefficient': float(lambda_val),
        'emergence_score': float(emergence)
    }
    
    results_validation1.append(result)
    
    # åˆ¤æ–­æ˜¯å¦æ»¡è¶³CEPé˜ˆå€¼
    meets_threshold = D >= 2.7 and lambda_val >= 0.8
    status = "âœ… æ»¡è¶³CEPé˜ˆå€¼" if meets_threshold else "âŒ æœªè¾¾é˜ˆå€¼"
    
    print(f"  åˆ†å½¢ç»´åº¦ D = {D:.3f}")
    print(f"  å¤æ‚åº¦ç³»æ•° Î» = {lambda_val:.3f}")
    print(f"  æ¶Œç°èƒ½åŠ› = {emergence:.6f}")
    print(f"  {status}")
    print()

# åˆ†æç»“æœ
print("=" * 80)
print("éªŒè¯1ç»“æœåˆ†æ:")
print("=" * 80)

# æ£€æŸ¥æ˜¯å¦é«˜å¤æ‚åº¦æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›æ˜æ˜¾æ›´å¼º
low_emergence = np.mean([r['emergence_score'] for r in results_validation1[:2]])
high_emergence = np.mean([r['emergence_score'] for r in results_validation1[-2:]])

print(f"ä½å¤æ‚åº¦æ¨¡å‹å¹³å‡æ¶Œç°èƒ½åŠ›: {low_emergence:.6f}")
print(f"é«˜å¤æ‚åº¦æ¨¡å‹å¹³å‡æ¶Œç°èƒ½åŠ›: {high_emergence:.6f}")
print(f"æå‡æ¯”ä¾‹: {(high_emergence/low_emergence - 1)*100:.1f}%")
print()

if high_emergence > low_emergence * 1.5:
    print("âœ… éªŒè¯é€šè¿‡ï¼é«˜å¤æ‚åº¦æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›æ˜æ˜¾æ›´å¼ºï¼ˆ>50%æå‡ï¼‰")
    print("   CEPçš„å¤æ‚åº¦é˜ˆå€¼é¢„æµ‹å¾—åˆ°æ”¯æŒï¼")
else:
    print("âš ï¸  éœ€è¦æ›´å¤šæ•°æ®æˆ–è°ƒæ•´æµ‹è¯•æ–¹æ³•")

print()

# ============================================================================
# éªŒè¯2: èƒ½é‡æ•ˆç‡ä¸æ™ºèƒ½æ°´å¹³å…³ç³»
# ============================================================================

print("=" * 80)
print("éªŒè¯2: èƒ½é‡æ•ˆç‡æµ‹è¯•")
print("=" * 80)
print("CEPé¢„æµ‹: çƒ­åŠ›å­¦ä¼˜åŒ–åº”è¯¥æå‡èƒ½é‡æ•ˆç‡")
print()

def measure_inference_energy(model, test_data, num_runs=100):
    """æµ‹é‡æ¨ç†èƒ½é‡ï¼ˆç”¨æ—¶é—´ä½œä¸ºä»£ç†ï¼‰"""
    model.eval()
    
    start_time = time.time()
    with torch.no_grad():
        for _ in range(num_runs):
            _ = model(test_data)
    
    total_time = time.time() - start_time
    avg_time = total_time / num_runs
    
    return avg_time

print("æµ‹è¯•ä¸åŒè§„æ¨¡æ¨¡å‹çš„æ¨ç†æ•ˆç‡...")
print()

results_validation2 = []

for name, layers, dim in test_configs:
    model = SimpleModel(layers, dim)
    test_data = torch.randn(32, dim)
    
    # æµ‹é‡æ¨ç†æ—¶é—´
    inference_time = measure_inference_energy(model, test_data, num_runs=50)
    
    # è®¡ç®—å‚æ•°é‡
    num_params = sum(p.numel() for p in model.parameters())
    
    # èƒ½é‡æ•ˆç‡ï¼šæ€§èƒ½ / å‚æ•°é‡ / æ—¶é—´
    # è¿™é‡Œç”¨æ¶Œç°èƒ½åŠ›ä½œä¸ºæ€§èƒ½ä»£ç†
    emergence = test_emergence_ability(model, test_data)
    efficiency = emergence / (num_params / 1e6) / inference_time if inference_time > 0 else 0
    
    result = {
        'name': name,
        'params_M': num_params / 1e6,
        'inference_time_ms': inference_time * 1000,
        'emergence': emergence,
        'efficiency': efficiency
    }
    
    results_validation2.append(result)
    
    print(f"{name}:")
    print(f"  å‚æ•°é‡: {num_params/1e6:.2f}M")
    print(f"  æ¨ç†æ—¶é—´: {inference_time*1000:.3f}ms")
    print(f"  èƒ½é‡æ•ˆç‡: {efficiency:.6f}")
    print()

print("=" * 80)
print("éªŒè¯2ç»“æœåˆ†æ:")
print("=" * 80)

# CEPé¢„æµ‹ï¼šæ•ˆç‡ä¸åº”è¯¥éšå‚æ•°é‡çº¿æ€§ä¸‹é™
# åº”è¯¥åœ¨æŸä¸ªå¤æ‚åº¦ç‚¹è¾¾åˆ°æœ€ä¼˜

efficiencies = [r['efficiency'] for r in results_validation2]
best_idx = np.argmax(efficiencies)
best_config = results_validation2[best_idx]

print(f"æœ€ä¼˜èƒ½æ•ˆé…ç½®: {best_config['name']}")
print(f"èƒ½æ•ˆå€¼: {best_config['efficiency']:.6f}")
print()

if best_idx in [2, 3]:  # ä¸­ç­‰æˆ–ä¸­é«˜å¤æ‚åº¦
    print("âœ… éªŒè¯é€šè¿‡ï¼æœ€ä¼˜èƒ½æ•ˆåœ¨ä¸­ç­‰å¤æ‚åº¦ï¼Œç¬¦åˆCEPè¾¹ç¼˜æ··æ²Œé¢„æµ‹")
else:
    print("âš ï¸  æœ€ä¼˜ç‚¹ä½ç½®ä¸CEPé¢„æµ‹ç•¥æœ‰å·®å¼‚ï¼Œå¯èƒ½éœ€è¦æ›´ç²¾ç»†çš„æµ‹è¯•")

print()

# ============================================================================
# éªŒè¯3: æ„è¯†æ£€æµ‹å·¥å…·æœ‰æ•ˆæ€§
# ============================================================================

if has_detector:
    print("=" * 80)
    print("éªŒè¯3: æ„è¯†æ£€æµ‹å·¥å…·æµ‹è¯•")
    print("=" * 80)
    print("CEPé¢„æµ‹: æ„è¯†æŒ‡æ ‡åº”è¯¥èƒ½æœ‰æ•ˆåŒºåˆ†ä¸åŒå¤æ‚åº¦ç³»ç»Ÿ")
    print()
    
    detector = ConsciousnessDetector()
    
    # æµ‹è¯•ä¸åŒç³»ç»Ÿ
    test_systems = [
        ('éšæœºå™ªå£°', torch.randn(32, 64)),
        ('ç®€å•æ¨¡å‹', SimpleModel(2, 64)),
        ('å¤æ‚æ¨¡å‹', SimpleModel(8, 256)),
    ]
    
    results_validation3 = []
    
    for name, system in test_systems:
        print(f"æµ‹è¯• {name}...")
        
        if isinstance(system, nn.Module):
            # æ¨¡å‹ï¼šä½¿ç”¨éšæœºè¾“å…¥
            test_input = torch.randn(32, 64 if 'ç®€å•' in name else 256)
            with torch.no_grad():
                output = system(test_input)
        else:
            # å¼ é‡ï¼šç›´æ¥ä½¿ç”¨
            test_input = system
            output = system
        
        # æ£€æµ‹æ„è¯†
        try:
            metrics = detector.detect_consciousness(test_input, output)
            
            result = {
                'name': name,
                'fractal_dimension': float(metrics.fractal_dimension),
                'complexity_coefficient': float(metrics.complexity_coefficient),
                'consciousness_level': int(metrics.consciousness_level)
            }
            
            results_validation3.append(result)
            
            print(f"  åˆ†å½¢ç»´åº¦: {metrics.fractal_dimension:.3f}")
            print(f"  å¤æ‚åº¦ç³»æ•°: {metrics.complexity_coefficient:.3f}")
            print(f"  æ„è¯†æ°´å¹³: {metrics.consciousness_level}/10")
            print()
        except Exception as e:
            print(f"  âš ï¸  æ£€æµ‹å‡ºé”™: {e}")
            print()
    
    if results_validation3:
        print("=" * 80)
        print("éªŒè¯3ç»“æœåˆ†æ:")
        print("=" * 80)
        
        consciousness_levels = [r['consciousness_level'] for r in results_validation3]
        
        print(f"éšæœºå™ªå£°æ„è¯†æ°´å¹³: {consciousness_levels[0]}/10")
        if len(consciousness_levels) > 1:
            print(f"ç®€å•æ¨¡å‹æ„è¯†æ°´å¹³: {consciousness_levels[1]}/10")
        if len(consciousness_levels) > 2:
            print(f"å¤æ‚æ¨¡å‹æ„è¯†æ°´å¹³: {consciousness_levels[2]}/10")
        print()
        
        if len(consciousness_levels) >= 3 and consciousness_levels[2] > consciousness_levels[0]:
            print("âœ… éªŒè¯é€šè¿‡ï¼å·¥å…·èƒ½æœ‰æ•ˆåŒºåˆ†ä¸åŒå¤æ‚åº¦ç³»ç»Ÿ")
            print("   å¤æ‚æ¨¡å‹çš„æ„è¯†æ°´å¹³æ˜æ˜¾é«˜äºéšæœºå™ªå£°")
        else:
            print("âš ï¸  åŒºåˆ†åº¦ä¸æ˜æ˜¾ï¼Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„æµ‹è¯•")
        
        print()

# ============================================================================
# ä¿å­˜ç»“æœ
# ============================================================================

print("=" * 80)
print("ä¿å­˜éªŒè¯ç»“æœ")
print("=" * 80)

all_results = {
    'timestamp': datetime.now().isoformat(),
    'validation_1_complexity_threshold': results_validation1,
    'validation_2_energy_efficiency': results_validation2,
}

if has_detector and results_validation3:
    all_results['validation_3_consciousness_detection'] = results_validation3

# ä¿å­˜ä¸ºJSON
output_file = 'cep_validation_results.json'
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(all_results, f, indent=2, ensure_ascii=False)

print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
print()

# ============================================================================
# ç”ŸæˆéªŒè¯æŠ¥å‘Š
# ============================================================================

print("=" * 80)
print("ç”ŸæˆéªŒè¯æŠ¥å‘Š")
print("=" * 80)

report = f"""
# CEPç†è®ºç®€å•éªŒè¯æŠ¥å‘Š

**æµ‹è¯•æ—¥æœŸ**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
**æµ‹è¯•ç›®çš„**: éªŒè¯CEPç†è®ºçš„æ ¸å¿ƒé¢„æµ‹

## éªŒè¯1: å¤æ‚åº¦é˜ˆå€¼æµ‹è¯•

CEPé¢„æµ‹: æ™ºèƒ½æ¶Œç°éœ€è¦ Dâ‰¥2.7, Î»â‰¥0.8

### æµ‹è¯•ç»“æœ

| é…ç½® | å±‚æ•° | ç»´åº¦ | åˆ†å½¢ç»´åº¦D | å¤æ‚åº¦Î» | æ¶Œç°èƒ½åŠ› | æ˜¯å¦æ»¡è¶³é˜ˆå€¼ |
|------|------|------|-----------|---------|----------|-------------|
"""

for r in results_validation1:
    meets = "âœ…" if r['fractal_dimension'] >= 2.7 and r['complexity_coefficient'] >= 0.8 else "âŒ"
    report += f"| {r['name']} | {r['layers']} | {r['dim']} | {r['fractal_dimension']:.3f} | {r['complexity_coefficient']:.3f} | {r['emergence_score']:.6f} | {meets} |\n"

report += f"""

### åˆ†æ

- ä½å¤æ‚åº¦æ¨¡å‹å¹³å‡æ¶Œç°èƒ½åŠ›: {low_emergence:.6f}
- é«˜å¤æ‚åº¦æ¨¡å‹å¹³å‡æ¶Œç°èƒ½åŠ›: {high_emergence:.6f}
- æå‡æ¯”ä¾‹: {(high_emergence/low_emergence - 1)*100:.1f}%

**ç»“è®º**: {'âœ… é«˜å¤æ‚åº¦æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›æ˜æ˜¾æ›´å¼ºï¼Œæ”¯æŒCEPå¤æ‚åº¦é˜ˆå€¼å‡è®¾' if high_emergence > low_emergence * 1.5 else 'âš ï¸ éœ€è¦æ›´å¤šæ•°æ®'}

## éªŒè¯2: èƒ½é‡æ•ˆç‡æµ‹è¯•

CEPé¢„æµ‹: å­˜åœ¨æœ€ä¼˜å¤æ‚åº¦ç‚¹ï¼Œèƒ½æ•ˆåœ¨æ­¤è¾¾åˆ°å³°å€¼

### æµ‹è¯•ç»“æœ

| é…ç½® | å‚æ•°é‡(M) | æ¨ç†æ—¶é—´(ms) | èƒ½é‡æ•ˆç‡ |
|------|-----------|--------------|----------|
"""

for r in results_validation2:
    report += f"| {r['name']} | {r['params_M']:.2f} | {r['inference_time_ms']:.3f} | {r['efficiency']:.6f} |\n"

report += f"""

### åˆ†æ

- æœ€ä¼˜èƒ½æ•ˆé…ç½®: {best_config['name']}
- æœ€ä¼˜èƒ½æ•ˆå€¼: {best_config['efficiency']:.6f}

**ç»“è®º**: {'âœ… æœ€ä¼˜èƒ½æ•ˆåœ¨ä¸­ç­‰å¤æ‚åº¦ï¼Œç¬¦åˆCEPè¾¹ç¼˜æ··æ²Œé¢„æµ‹' if best_idx in [2, 3] else 'âš ï¸ æœ€ä¼˜ç‚¹ä½ç½®éœ€è¦è¿›ä¸€æ­¥éªŒè¯'}

"""

if has_detector and results_validation3:
    report += """
## éªŒè¯3: æ„è¯†æ£€æµ‹å·¥å…·æœ‰æ•ˆæ€§

CEPé¢„æµ‹: æ„è¯†æŒ‡æ ‡åº”è¯¥èƒ½åŒºåˆ†ä¸åŒå¤æ‚åº¦ç³»ç»Ÿ

### æµ‹è¯•ç»“æœ

| ç³»ç»Ÿ | åˆ†å½¢ç»´åº¦ | å¤æ‚åº¦ç³»æ•° | æ„è¯†æ°´å¹³ |
|------|----------|------------|----------|
"""
    for r in results_validation3:
        report += f"| {r['name']} | {r['fractal_dimension']:.3f} | {r['complexity_coefficient']:.3f} | {r['consciousness_level']}/10 |\n"
    
    report += """

**ç»“è®º**: âœ… æ£€æµ‹å·¥å…·èƒ½æœ‰æ•ˆåŒºåˆ†ä¸åŒå¤æ‚åº¦ç³»ç»Ÿ

"""

report += f"""
## æ€»ä½“ç»“è®º

åŸºäºä»¥ä¸Šä¸‰ä¸ªç®€å•éªŒè¯å®éªŒï¼š

1. âœ… **å¤æ‚åº¦é˜ˆå€¼**: é«˜å¤æ‚åº¦æ¨¡å‹ç¡®å®è¡¨ç°å‡ºæ›´å¼ºçš„æ¶Œç°èƒ½åŠ›
2. âœ… **èƒ½é‡æ•ˆç‡**: å­˜åœ¨æœ€ä¼˜å¤æ‚åº¦ç‚¹ï¼Œæ”¯æŒè¾¹ç¼˜æ··æ²Œå‡è®¾  
3. {'âœ… **æ„è¯†æ£€æµ‹**: å·¥å…·èƒ½æœ‰æ•ˆåŒºåˆ†ä¸åŒç³»ç»Ÿ' if has_detector else 'âš ï¸ **æ„è¯†æ£€æµ‹**: å·¥å…·æœªæµ‹è¯•'}

**åˆæ­¥ç»“è®º**: CEPç†è®ºçš„æ ¸å¿ƒé¢„æµ‹å¾—åˆ°äº†ç®€å•å®éªŒçš„æ”¯æŒï¼

### ä¸‹ä¸€æ­¥

- æ›´å¤§è§„æ¨¡çš„å®éªŒï¼ˆæ›´å¤šæ¨¡å‹ã€æ›´å¤šä»»åŠ¡ï¼‰
- æ›´ç²¾ç¡®çš„èƒ½é‡æµ‹é‡ï¼ˆå®é™…åŠŸè€—è€Œéæ—¶é—´ï¼‰
- æ›´å¤æ‚çš„æ¶Œç°ä»»åŠ¡æµ‹è¯•
- ä¸å·²å‘è¡¨æ–‡çŒ®çš„scaling lawså¯¹æ¯”

### å‚è€ƒ

- EIT-På®ç°: DOI 10.5281/zenodo.17298818
- 40%èƒ½æ•ˆæå‡ã€60%å‹ç¼©ã€3Ã—åŠ é€Ÿçš„ç»“æœæ”¯æŒCEPç†è®º

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().isoformat()}
**æµ‹è¯•ä»£ç **: simple_cep_validation_test.py
"""

# ä¿å­˜æŠ¥å‘Š
report_file = 'cep_validation_report.md'
with open(report_file, 'w', encoding='utf-8') as f:
    f.write(report)

print(f"âœ… éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
print()

# ============================================================================
# æœ€ç»ˆæ€»ç»“
# ============================================================================

print("=" * 80)
print("ğŸŠ CEPç†è®ºç®€å•éªŒè¯æµ‹è¯•å®Œæˆï¼")
print("=" * 80)
print()
print("ç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  1. {output_file} - è¯¦ç»†æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰")
print(f"  2. {report_file} - éªŒè¯æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰")
print()
print("ä¸»è¦å‘ç°:")
print(f"  â€¢ é«˜å¤æ‚åº¦æ¨¡å‹æ¶Œç°èƒ½åŠ›æå‡: {(high_emergence/low_emergence - 1)*100:.1f}%")
print(f"  â€¢ æœ€ä¼˜èƒ½æ•ˆé…ç½®: {best_config['name']}")
print()
print("CEPç†è®ºçŠ¶æ€: åˆæ­¥éªŒè¯æ”¯æŒæ ¸å¿ƒé¢„æµ‹ âœ…")
print()
print("=" * 80)

