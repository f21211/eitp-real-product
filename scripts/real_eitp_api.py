#!/usr/bin/env python3
"""
EIT-P Production API Server
Emergent Intelligence Framework based on IEM Theory - Real Product Implementation
"""

import os
import sys
import json
import time
import logging
import asyncio
from datetime import datetime
from typing import Dict, List, Optional, Any
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ ¸å¿ƒä¾èµ–
import torch
import numpy as np
from flask import Flask, request, jsonify, g
from flask_cors import CORS
import jwt
from functools import wraps
import psutil
import yaml

# å¯¼å…¥transformers
from transformers import (
    GPT2LMHeadModel, 
    GPT2Tokenizer, 
    GPT2Config,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)

# å¯¼å…¥EIT-Pæ ¸å¿ƒæ¨¡å—
try:
    from eit_p_simple.experiments import ExperimentManager
    from eit_p_simple.models import ModelRegistry
    from eit_p_simple.metrics import MetricsTracker
    from eit_p_simple.security import SecurityManager
    from eit_p_simple.compression import ModelCompressor
    from eit_p_simple.optimization import HyperparameterOptimizer
    from eit_p_simple.distributed import DistributedTrainer
    from eit_p_simple.ab_testing import ABTestManager
    print("âœ… EIT-Pç®€åŒ–æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥EIT-Pæ¨¡å—: {e}")
    print("å°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬...")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('eitp_api.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class RealEITPAPI:
    """çœŸå®çš„EIT-P APIæœåŠ¡å™¨ - åŸºäºIEMç†è®ºçš„æ¶Œç°æ™ºèƒ½æ¡†æ¶"""
    
    def __init__(self, host='0.0.0.0', port=8085):
        self.app = Flask(__name__)
        CORS(self.app)
        self.host = host
        self.port = port
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.model = None
        self.tokenizer = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # é…ç½®
        self.config = self._load_config()
        self.jwt_secret = self.config.get('jwt_secret', 'eitp_jwt_secret_2025')
        
        # åˆå§‹åŒ–EIT-Pæ ¸å¿ƒæ¨¡å—
        self._init_eitp_modules()
        
        # è®¾ç½®è·¯ç”±
        self._setup_routes()
        
        logger.info(f"EIT-P APIæœåŠ¡å™¨åˆå§‹åŒ–å®Œæˆ - è®¾å¤‡: {self.device}")
    
    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®"""
        config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'production.yaml')
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.warning(f"æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶: {e}, ä½¿ç”¨é»˜è®¤é…ç½®")
            return {
                'jwt_secret': 'eitp_jwt_secret_2025',
                'model_name': 'gpt2',
                'max_length': 512,
                'temperature': 0.7,
                'top_p': 0.9
            }
    
    def _init_eitp_modules(self):
        """åˆå§‹åŒ–EIT-Pæ ¸å¿ƒæ¨¡å—"""
        try:
            # åˆå§‹åŒ–å®éªŒç®¡ç†å™¨
            self.experiment_manager = ExperimentManager()
            logger.info("âœ… å®éªŒç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æ¨¡å‹æ³¨å†Œè¡¨
            self.model_registry = ModelRegistry()
            logger.info("âœ… æ¨¡å‹æ³¨å†Œè¡¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æŒ‡æ ‡è·Ÿè¸ªå™¨
            self.metrics_tracker = MetricsTracker()
            logger.info("âœ… æŒ‡æ ‡è·Ÿè¸ªå™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–å®‰å…¨ç®¡ç†å™¨
            self.security_manager = SecurityManager()
            logger.info("âœ… å®‰å…¨ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æ¨¡å‹å‹ç¼©å™¨
            self.model_compressor = ModelCompressor()
            logger.info("âœ… æ¨¡å‹å‹ç¼©å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–è¶…å‚æ•°ä¼˜åŒ–å™¨
            self.hyperparameter_optimizer = HyperparameterOptimizer()
            logger.info("âœ… è¶…å‚æ•°ä¼˜åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒå™¨
            self.distributed_trainer = DistributedTrainer()
            logger.info("âœ… åˆ†å¸ƒå¼è®­ç»ƒå™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–A/Bæµ‹è¯•ç®¡ç†å™¨
            self.ab_test_manager = ABTestManager()
            logger.info("âœ… A/Bæµ‹è¯•ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"EIT-Pæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.info("ä½¿ç”¨ç®€åŒ–æ¨¡å¼è¿è¡Œ...")
    
    def _load_model(self):
        """åŠ è½½GPT-2æ¨¡å‹"""
        try:
            model_name = self.config.get('model_name', 'gpt2')
            logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
            
            # åŠ è½½tokenizer
            self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)
            self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # åŠ è½½æ¨¡å‹
            self.model = GPT2LMHeadModel.from_pretrained(model_name)
            self.model.to(self.device)
            self.model.eval()
            
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
            return True
            
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _setup_routes(self):
        """è®¾ç½®APIè·¯ç”±"""
        
        @self.app.route('/api/health', methods=['GET'])
        def health_check():
            """å¥åº·æ£€æŸ¥"""
            try:
                # æ£€æŸ¥ç³»ç»Ÿèµ„æº
                cpu_percent = psutil.cpu_percent()
                memory = psutil.virtual_memory()
                gpu_available = torch.cuda.is_available()
                
                health_data = {
                    'status': 'healthy',
                    'timestamp': datetime.now().isoformat(),
                    'version': '2.0.0',
                    'system': {
                        'cpu_percent': cpu_percent,
                        'memory_percent': memory.percent,
                        'gpu_available': gpu_available,
                        'device': str(self.device)
                    },
                    'eitp_modules': {
                        'experiment_manager': hasattr(self, 'experiment_manager'),
                        'model_registry': hasattr(self, 'model_registry'),
                        'metrics_tracker': hasattr(self, 'metrics_tracker'),
                        'security_manager': hasattr(self, 'security_manager'),
                        'model_compressor': hasattr(self, 'model_compressor'),
                        'hyperparameter_optimizer': hasattr(self, 'hyperparameter_optimizer'),
                        'distributed_trainer': hasattr(self, 'distributed_trainer'),
                        'ab_test_manager': hasattr(self, 'ab_test_manager')
                    }
                }
                
                return jsonify(health_data), 200
                
            except Exception as e:
                logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
                return jsonify({'status': 'error', 'message': str(e)}), 500
        
        @self.app.route('/api/inference', methods=['POST'])
        def inference():
            """æ¨ç†æ¥å£ - åŸºäºIEMç†è®ºçš„æ™ºèƒ½ç”Ÿæˆ"""
            try:
                data = request.get_json()
                if not data:
                    return jsonify({'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'}), 400
                
                prompt = data.get('prompt', '')
                max_length = data.get('max_length', self.config.get('max_length', 512))
                temperature = data.get('temperature', self.config.get('temperature', 0.7))
                top_p = data.get('top_p', self.config.get('top_p', 0.9))
                
                if not prompt:
                    return jsonify({'error': 'ç¼ºå°‘promptå‚æ•°'}), 400
                
                # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
                if self.model is None:
                    if not self._load_model():
                        return jsonify({'error': 'æ¨¡å‹åŠ è½½å¤±è´¥'}), 500
                
                # æ‰§è¡Œæ¨ç†
                start_time = time.time()
                
                # ç¼–ç è¾“å…¥
                inputs = self.tokenizer.encode(prompt, return_tensors='pt').to(self.device)
                
                # ç”Ÿæˆæ–‡æœ¬
                with torch.no_grad():
                    outputs = self.model.generate(
                        inputs,
                        max_length=max_length,
                        temperature=temperature,
                        top_p=top_p,
                        do_sample=True,
                        pad_token_id=self.tokenizer.eos_token_id,
                        eos_token_id=self.tokenizer.eos_token_id
                    )
                
                # è§£ç è¾“å‡º
                generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                response_text = generated_text[len(prompt):]
                
                inference_time = time.time() - start_time
                
                # è®°å½•æŒ‡æ ‡
                if hasattr(self, 'metrics_tracker'):
                    self.metrics_tracker.record_inference_metrics({
                        'prompt_length': len(prompt),
                        'response_length': len(response_text),
                        'inference_time': inference_time,
                        'temperature': temperature,
                        'top_p': top_p
                    })
                
                return jsonify({
                    'status': 'success',
                    'prompt': prompt,
                    'response': response_text,
                    'full_text': generated_text,
                    'metrics': {
                        'inference_time': inference_time,
                        'prompt_length': len(prompt),
                        'response_length': len(response_text),
                        'temperature': temperature,
                        'top_p': top_p
                    }
                }), 200
                
            except Exception as e:
                logger.error(f"æ¨ç†å¤±è´¥: {e}")
                return jsonify({'error': f'æ¨ç†å¤±è´¥: {str(e)}'}), 500
        
        @self.app.route('/api/experiments', methods=['POST'])
        def create_experiment():
            """åˆ›å»ºå®éªŒ"""
            try:
                if not hasattr(self, 'experiment_manager'):
                    return jsonify({'error': 'å®éªŒç®¡ç†å™¨æœªåˆå§‹åŒ–'}), 500
                
                data = request.get_json()
                if not data:
                    return jsonify({'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'}), 400
                
                experiment_id = self.experiment_manager.create_experiment(data)
                
                return jsonify({
                    'status': 'success',
                    'experiment_id': experiment_id,
                    'message': 'å®éªŒåˆ›å»ºæˆåŠŸ'
                }), 201
                
            except Exception as e:
                logger.error(f"åˆ›å»ºå®éªŒå¤±è´¥: {e}")
                return jsonify({'error': f'åˆ›å»ºå®éªŒå¤±è´¥: {str(e)}'}), 500
        
        @self.app.route('/api/experiments/<experiment_id>', methods=['GET'])
        def get_experiment(experiment_id):
            """è·å–å®éªŒä¿¡æ¯"""
            try:
                if not hasattr(self, 'experiment_manager'):
                    return jsonify({'error': 'å®éªŒç®¡ç†å™¨æœªåˆå§‹åŒ–'}), 500
                
                experiment = self.experiment_manager.get_experiment(experiment_id)
                if not experiment:
                    return jsonify({'error': 'å®éªŒä¸å­˜åœ¨'}), 404
                
                return jsonify({
                    'status': 'success',
                    'experiment': experiment
                }), 200
                
            except Exception as e:
                logger.error(f"è·å–å®éªŒå¤±è´¥: {e}")
                return jsonify({'error': f'è·å–å®éªŒå¤±è´¥: {str(e)}'}), 500
        
        @self.app.route('/api/models', methods=['GET'])
        def list_models():
            """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹"""
            try:
                if not hasattr(self, 'model_registry'):
                    return jsonify({'error': 'æ¨¡å‹æ³¨å†Œè¡¨æœªåˆå§‹åŒ–'}), 500
                
                models = self.model_registry.list_models()
                
                return jsonify({
                    'status': 'success',
                    'models': models
                }), 200
                
            except Exception as e:
                logger.error(f"åˆ—å‡ºæ¨¡å‹å¤±è´¥: {e}")
                return jsonify({'error': f'åˆ—å‡ºæ¨¡å‹å¤±è´¥: {str(e)}'}), 500
        
        @self.app.route('/api/metrics', methods=['GET'])
        def get_metrics():
            """è·å–ç³»ç»ŸæŒ‡æ ‡"""
            try:
                if not hasattr(self, 'metrics_tracker'):
                    return jsonify({'error': 'æŒ‡æ ‡è·Ÿè¸ªå™¨æœªåˆå§‹åŒ–'}), 500
                
                metrics = self.metrics_tracker.get_metrics()
                
                return jsonify({
                    'status': 'success',
                    'metrics': metrics
                }), 200
                
            except Exception as e:
                logger.error(f"è·å–æŒ‡æ ‡å¤±è´¥: {e}")
                return jsonify({'error': f'è·å–æŒ‡æ ‡å¤±è´¥: {str(e)}'}), 500
        
        @self.app.route('/api/compress', methods=['POST'])
        def compress_model():
            """æ¨¡å‹å‹ç¼©"""
            try:
                if not hasattr(self, 'model_compressor'):
                    return jsonify({'error': 'æ¨¡å‹å‹ç¼©å™¨æœªåˆå§‹åŒ–'}), 500
                
                data = request.get_json()
                if not data:
                    return jsonify({'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'}), 400
                
                model_id = data.get('model_id')
                compression_ratio = data.get('compression_ratio', 0.5)
                
                if not model_id:
                    return jsonify({'error': 'ç¼ºå°‘model_idå‚æ•°'}), 400
                
                # æ‰§è¡Œæ¨¡å‹å‹ç¼©
                compressed_model = self.model_compressor.compress_model(
                    model_id, compression_ratio
                )
                
                return jsonify({
                    'status': 'success',
                    'compressed_model': compressed_model,
                    'compression_ratio': compression_ratio
                }), 200
                
            except Exception as e:
                logger.error(f"æ¨¡å‹å‹ç¼©å¤±è´¥: {e}")
                return jsonify({'error': f'æ¨¡å‹å‹ç¼©å¤±è´¥: {str(e)}'}), 500
        
        @self.app.route('/api/optimize', methods=['POST'])
        def optimize_hyperparameters():
            """è¶…å‚æ•°ä¼˜åŒ–"""
            try:
                if not hasattr(self, 'hyperparameter_optimizer'):
                    return jsonify({'error': 'è¶…å‚æ•°ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–'}), 500
                
                data = request.get_json()
                if not data:
                    return jsonify({'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'}), 400
                
                # æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–
                best_params = self.hyperparameter_optimizer.optimize(data)
                
                return jsonify({
                    'status': 'success',
                    'best_parameters': best_params
                }), 200
                
            except Exception as e:
                logger.error(f"è¶…å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
                return jsonify({'error': f'è¶…å‚æ•°ä¼˜åŒ–å¤±è´¥: {str(e)}'}), 500
        
        @self.app.route('/api/ab_test', methods=['POST'])
        def create_ab_test():
            """åˆ›å»ºA/Bæµ‹è¯•"""
            try:
                if not hasattr(self, 'ab_test_manager'):
                    return jsonify({'error': 'A/Bæµ‹è¯•ç®¡ç†å™¨æœªåˆå§‹åŒ–'}), 500
                
                data = request.get_json()
                if not data:
                    return jsonify({'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'}), 400
                
                test_id = self.ab_test_manager.create_test(data)
                
                return jsonify({
                    'status': 'success',
                    'test_id': test_id,
                    'message': 'A/Bæµ‹è¯•åˆ›å»ºæˆåŠŸ'
                }), 201
                
            except Exception as e:
                logger.error(f"åˆ›å»ºA/Bæµ‹è¯•å¤±è´¥: {e}")
                return jsonify({'error': f'åˆ›å»ºA/Bæµ‹è¯•å¤±è´¥: {str(e)}'}), 500
        
        @self.app.route('/', methods=['GET'])
        def welcome():
            """æ¬¢è¿é¡µé¢"""
            return jsonify({
                'message': 'ğŸ‰ æ¬¢è¿ä½¿ç”¨EIT-Pæ¡†æ¶ï¼',
                'description': 'åŸºäºIEMç†è®ºçš„æ¶Œç°æ™ºèƒ½æ¡†æ¶ - çœŸå®äº§å“',
                'version': '2.0.0',
                'status': 'running',
                'api_endpoints': {
                    'health': '/api/health',
                    'inference': '/api/inference',
                    'experiments': '/api/experiments',
                    'models': '/api/models',
                    'metrics': '/api/metrics',
                    'compress': '/api/compress',
                    'optimize': '/api/optimize',
                    'ab_test': '/api/ab_test',
                    'status': '/api/status'
                },
                'documentation': 'è¯·æŸ¥çœ‹ README.md äº†è§£è¯¦ç»†ä½¿ç”¨æ–¹æ³•',
                'timestamp': datetime.now().isoformat()
            }), 200
        
        @self.app.route('/api/status', methods=['GET'])
        def get_status():
            """è·å–ç³»ç»ŸçŠ¶æ€"""
            try:
                # ç³»ç»Ÿèµ„æºçŠ¶æ€
                cpu_percent = psutil.cpu_percent()
                memory = psutil.virtual_memory()
                disk = psutil.disk_usage('/')
                
                # GPUçŠ¶æ€
                gpu_info = []
                if torch.cuda.is_available():
                    for i in range(torch.cuda.device_count()):
                        gpu_info.append({
                            'device_id': i,
                            'name': torch.cuda.get_device_name(i),
                            'memory_allocated': torch.cuda.memory_allocated(i),
                            'memory_reserved': torch.cuda.memory_reserved(i),
                            'memory_total': torch.cuda.get_device_properties(i).total_memory
                        })
                
                status = {
                    'timestamp': datetime.now().isoformat(),
                    'system': {
                        'cpu_percent': cpu_percent,
                        'memory_percent': memory.percent,
                        'disk_percent': disk.percent,
                        'gpu_count': torch.cuda.device_count(),
                        'gpu_info': gpu_info
                    },
                    'eitp_status': {
                        'model_loaded': self.model is not None,
                        'modules_initialized': hasattr(self, 'experiment_manager'),
                        'device': str(self.device)
                    }
                }
                
                return jsonify({
                    'status': 'success',
                    'data': status
                }), 200
                
            except Exception as e:
                logger.error(f"è·å–çŠ¶æ€å¤±è´¥: {e}")
                return jsonify({'error': f'è·å–çŠ¶æ€å¤±è´¥: {str(e)}'}), 500
    
    def run(self, debug=False):
        """è¿è¡ŒAPIæœåŠ¡å™¨"""
        try:
            logger.info(f"ğŸš€ å¯åŠ¨EIT-P APIæœåŠ¡å™¨...")
            logger.info(f"ğŸ“ åœ°å€: http://{self.host}:{self.port}")
            logger.info(f"ğŸ”§ è®¾å¤‡: {self.device}")
            logger.info(f"ğŸ§  æ¨¡å‹: {self.config.get('model_name', 'gpt2')}")
            
            self.app.run(
                host=self.host,
                port=self.port,
                debug=debug,
                threaded=True
            )
            
        except Exception as e:
            logger.error(f"APIæœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºAPIæœåŠ¡å™¨å®ä¾‹
        api_server = RealEITPAPI(host='0.0.0.0', port=8085)
        
        # è¿è¡ŒæœåŠ¡å™¨
        api_server.run(debug=False)
        
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡å™¨...")
    except Exception as e:
        logger.error(f"æœåŠ¡å™¨è¿è¡Œå¤±è´¥: {e}")
        traceback.print_exc()

if __name__ == '__main__':
    main()
