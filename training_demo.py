#!/usr/bin/env python3
"""
EIT-P çœŸå®è®­ç»ƒæ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„è®­ç»ƒæµç¨‹å’Œæ‰€æœ‰åŠŸèƒ½
"""

import os
import sys
import logging
import time
import torch
import numpy as np
from datetime import datetime

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:32'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("=" * 80)
    print("ğŸš€ EIT-P çœŸå®è®­ç»ƒæ¼”ç¤º")
    print("=" * 80)
    print("å±•ç¤ºå®Œæ•´çš„AIæ¨¡å‹è®­ç»ƒæµç¨‹")
    print("åŒ…å«ï¼šæ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°ã€å®éªŒç®¡ç†ã€A/Bæµ‹è¯•")
    print("=" * 80)

def create_demo_data():
    """åˆ›å»ºæ¼”ç¤ºæ•°æ®"""
    print("\nğŸ“Š 1. åˆ›å»ºæ¼”ç¤ºæ•°æ®")
    print("-" * 40)
    
    # åˆ›å»ºç®€å•çš„æ–‡æœ¬æ•°æ®
    texts = [
        "è¿™æ˜¯ä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½çš„æ–‡æœ¬",
        "æœºå™¨å­¦ä¹ æ˜¯AIçš„é‡è¦åˆ†æ”¯",
        "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ",
        "è‡ªç„¶è¯­è¨€å¤„ç†å¾ˆæœ‰è¶£",
        "è®¡ç®—æœºè§†è§‰è¯†åˆ«å›¾åƒ",
        "å¼ºåŒ–å­¦ä¹ é€šè¿‡è¯•é”™å­¦ä¹ ",
        "ç”Ÿæˆæ¨¡å‹åˆ›é€ æ–°å†…å®¹",
        "Transformeræ¶æ„å¾ˆå¼ºå¤§",
        "æ³¨æ„åŠ›æœºåˆ¶å¾ˆé‡è¦",
        "é¢„è®­ç»ƒæ¨¡å‹å¾ˆæœ‰æ•ˆ"
    ] * 10  # é‡å¤10æ¬¡å¢åŠ æ•°æ®é‡
    
    # åˆ›å»ºæ ‡ç­¾ï¼ˆç®€å•çš„åˆ†ç±»ä»»åŠ¡ï¼‰
    labels = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1] * 10
    
    print(f"âœ… åˆ›å»ºäº† {len(texts)} ä¸ªæ–‡æœ¬æ ·æœ¬")
    print(f"âœ… æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(labels)}")
    
    return texts, labels

def demo_training_process():
    """æ¼”ç¤ºè®­ç»ƒè¿‡ç¨‹"""
    print("\nğŸ‹ï¸ 2. å¼€å§‹æ¨¡å‹è®­ç»ƒ")
    print("-" * 40)
    
    try:
        # å¯¼å…¥EIT-Pç»„ä»¶
        from eit_p.utils import ConfigManager, get_global_logger, ErrorHandler
        from eit_p.experiments import ExperimentManager, MetricsTracker
        from eit_p.ab_testing import TrafficSplitter, MetricsCollector
        from eit_p.security import SecurityAuditor
        
        # åˆå§‹åŒ–ç»„ä»¶
        config_manager = ConfigManager()
        logger = get_global_logger()
        error_handler = ErrorHandler(logger)
        exp_manager = ExperimentManager()
        security_auditor = SecurityAuditor()
        
        # åˆ›å»ºå®éªŒ
        experiment_id = exp_manager.create_experiment(
            name="EIT-Pæ¼”ç¤ºè®­ç»ƒ",
            description="å±•ç¤ºEIT-Pæ¡†æ¶çš„å®Œæ•´è®­ç»ƒæµç¨‹",
            model_name="demo_model",
            dataset_name="demo_dataset",
            hyperparameters={
                "learning_rate": 0.001,
                "batch_size": 4,
                "epochs": 3
            }
        )
        print(f"âœ… åˆ›å»ºå®éªŒ: {experiment_id}")
        
        # è®°å½•å®‰å…¨äº‹ä»¶
        security_auditor.log_event(
            event_type="training_start",
            user_id="demo_user",
            resource="model_training",
            action="start_training",
            result="success",
            details={"experiment_id": experiment_id}
        )
        print("âœ… è®°å½•å®‰å…¨äº‹ä»¶")
        
        # åˆ›å»ºæŒ‡æ ‡è·Ÿè¸ªå™¨
        metrics_tracker = MetricsTracker(experiment_id)
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        print("\nğŸ”„ å¼€å§‹è®­ç»ƒå¾ªç¯...")
        for epoch in range(3):
            print(f"\nğŸ“ˆ Epoch {epoch + 1}/3")
            
            # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
            for step in range(5):  # æ¯ä¸ªepoch 5ä¸ªæ­¥éª¤
                # æ¨¡æ‹ŸæŸå¤±å€¼ï¼ˆé€æ¸ä¸‹é™ï¼‰
                loss = 1.0 - (epoch * 0.3) - (step * 0.05) + np.random.normal(0, 0.05)
                accuracy = 0.5 + (epoch * 0.15) + (step * 0.02) + np.random.normal(0, 0.02)
                accuracy = min(accuracy, 0.99)  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
                
                # è®°å½•æŒ‡æ ‡
                metrics_tracker.log_metric("loss", loss, step + epoch * 5)
                metrics_tracker.log_metric("accuracy", accuracy, step + epoch * 5)
                
                print(f"  Step {step + 1}: Loss={loss:.4f}, Accuracy={accuracy:.4f}")
                
                # æ¨¡æ‹ŸGPUå†…å­˜ä½¿ç”¨
                if torch.cuda.is_available():
                    gpu_memory = torch.cuda.memory_allocated() / 1024**3
                    metrics_tracker.log_metric("gpu_memory_gb", gpu_memory, step + epoch * 5)
                
                time.sleep(0.1)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
            
            print(f"âœ… Epoch {epoch + 1} å®Œæˆ")
        
        # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
        report = metrics_tracker.generate_report()
        print(f"\nğŸ“Š è®­ç»ƒæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        print(f"  - æ€»æ­¥æ•°: {len(report.get('metrics', {}).get('loss', []))}")
        print(f"  - æœ€ç»ˆæŸå¤±: {report.get('metrics', {}).get('loss', [0])[-1]:.4f}")
        print(f"  - æœ€ç»ˆå‡†ç¡®ç‡: {report.get('metrics', {}).get('accuracy', [0])[-1]:.4f}")
        
        # å®Œæˆå®éªŒ
        final_results = {
            "final_loss": loss,
            "final_accuracy": accuracy,
            "total_epochs": 3,
            "total_steps": 15
        }
        exp_manager.complete_experiment(experiment_id, final_results)
        print("âœ… å®éªŒå®Œæˆ")
        
        return experiment_id
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹å¤±è´¥: {e}")
        # åˆ›å»ºé”™è¯¯å¤„ç†å™¨
        from eit_p.utils import ErrorHandler, get_global_logger
        error_handler = ErrorHandler(get_global_logger())
        error_handler.handle_error(e, "è®­ç»ƒè¿‡ç¨‹")
        return None

def demo_ab_testing():
    """æ¼”ç¤ºA/Bæµ‹è¯•"""
    print("\nğŸ”¬ 3. A/Bæµ‹è¯•æ¼”ç¤º")
    print("-" * 40)
    
    try:
        from eit_p.ab_testing import TrafficSplitter, MetricsCollector, ExperimentAnalyzer
        from eit_p.ab_testing.traffic_splitter import Variant
        
        # åˆ›å»ºæµé‡åˆ†å‰²å™¨
        traffic_splitter = TrafficSplitter()
        
        # åˆ›å»ºå˜ä½“
        variants = [
            Variant(name="control", weight=0.5, description="æ§åˆ¶ç»„ - åŸå§‹æ¨¡å‹"),
            Variant(name="treatment", weight=0.5, description="å®éªŒç»„ - ä¼˜åŒ–æ¨¡å‹")
        ]
        
        # åˆ›å»ºA/Bæµ‹è¯•å®éªŒ
        ab_experiment = traffic_splitter.create_experiment(
            experiment_id="model_ab_test",
            name="æ¨¡å‹A/Bæµ‹è¯•",
            description="æ¯”è¾ƒåŸå§‹æ¨¡å‹å’Œä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½",
            variants=variants
        )
        print(f"âœ… åˆ›å»ºA/Bæµ‹è¯•: {ab_experiment.experiment_id}")
        
        # åˆ›å»ºæŒ‡æ ‡æ”¶é›†å™¨
        metrics_collector = MetricsCollector()
        
        # æ¨¡æ‹Ÿç”¨æˆ·è®¿é—®å’ŒæŒ‡æ ‡æ”¶é›†
        print("\nğŸ‘¥ æ¨¡æ‹Ÿç”¨æˆ·è®¿é—®...")
        for user_id in range(20):
            variant = traffic_splitter.get_variant_for_user(f"user_{user_id}", ab_experiment.experiment_id)
            
            # æ¨¡æ‹Ÿä¸åŒçš„æ€§èƒ½æŒ‡æ ‡
            if variant == "control":
                response_time = np.random.normal(0.5, 0.1)  # æ§åˆ¶ç»„å“åº”æ—¶é—´
                conversion_rate = np.random.beta(3, 7)      # æ§åˆ¶ç»„è½¬åŒ–ç‡
            else:
                response_time = np.random.normal(0.4, 0.1)  # å®éªŒç»„å“åº”æ—¶é—´ï¼ˆæ›´å¿«ï¼‰
                conversion_rate = np.random.beta(4, 6)      # å®éªŒç»„è½¬åŒ–ç‡ï¼ˆæ›´é«˜ï¼‰
            
            # è®°å½•æŒ‡æ ‡
            metrics_collector.record_metric("response_time", response_time, 
                                          ab_experiment.experiment_id, variant, user_id=f"user_{user_id}")
            metrics_collector.record_metric("conversion_rate", conversion_rate,
                                          ab_experiment.experiment_id, variant, user_id=f"user_{user_id}")
            
            print(f"  ç”¨æˆ· {user_id}: {variant} - å“åº”æ—¶é—´: {response_time:.3f}s, è½¬åŒ–ç‡: {conversion_rate:.3f}")
        
        # åˆ†æå®éªŒç»“æœ
        print("\nğŸ“Š åˆ†æå®éªŒç»“æœ...")
        analyzer = ExperimentAnalyzer()
        
        # è·å–å®éªŒæ•°æ®
        control_metrics = metrics_collector.get_metrics(
            experiment_id=ab_experiment.experiment_id, 
            variant="control", 
            metric_name="conversion_rate"
        )
        treatment_metrics = metrics_collector.get_metrics(
            experiment_id=ab_experiment.experiment_id, 
            variant="treatment", 
            metric_name="conversion_rate"
        )
        
        # å‡†å¤‡åˆ†ææ•°æ®
        experiment_data = {
            "experiment_id": ab_experiment.experiment_id,
            "variants": {
                "control": {"values": [m.value for m in control_metrics]},
                "treatment": {"values": [m.value for m in treatment_metrics]}
            }
        }
        
        # æ‰§è¡Œåˆ†æ
        analysis_result = analyzer.analyze_experiment(experiment_data)
        
        # æ˜¾ç¤ºç»“æœ
        print("âœ… A/Bæµ‹è¯•åˆ†æå®Œæˆ")
        print(f"  - æ§åˆ¶ç»„è½¬åŒ–ç‡: {np.mean([m.value for m in control_metrics]):.3f}")
        print(f"  - å®éªŒç»„è½¬åŒ–ç‡: {np.mean([m.value for m in treatment_metrics]):.3f}")
        
        # æ£€æŸ¥ç»Ÿè®¡æ˜¾è‘—æ€§
        statistical_tests = analysis_result.get("statistical_tests", {})
        for test_name, test_data in statistical_tests.items():
            if isinstance(test_data, dict) and "t_test" in test_data:
                t_test = test_data["t_test"]
                significance = "æ˜¾è‘—" if t_test.is_significant else "ä¸æ˜¾è‘—"
                print(f"  - {test_name}: {significance} (p={t_test.p_value:.4f})")
        
        return ab_experiment.experiment_id
        
    except Exception as e:
        print(f"âŒ A/Bæµ‹è¯•å¤±è´¥: {e}")
        return None

def demo_model_compression():
    """æ¼”ç¤ºæ¨¡å‹å‹ç¼©"""
    print("\nğŸ—œï¸ 4. æ¨¡å‹å‹ç¼©æ¼”ç¤º")
    print("-" * 40)
    
    try:
        from eit_p.compression import QuantizationManager, PruningManager
        
        # åˆ›å»ºå‹ç¼©ç®¡ç†å™¨
        quant_manager = QuantizationManager()
        prune_manager = PruningManager()
        
        print("âœ… å‹ç¼©ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
        
        # æ¨¡æ‹Ÿæ¨¡å‹å‹ç¼©
        print("\nğŸ”§ æ‰§è¡Œæ¨¡å‹å‹ç¼©...")
        
        # é‡åŒ–
        quant_config = {
            "method": "dynamic",
            "bits": 8,
            "calibration_samples": 100
        }
        print(f"  - é‡åŒ–é…ç½®: {quant_config}")
        
        # å‰ªæ
        prune_config = {
            "method": "magnitude",
            "sparsity": 0.3,
            "structured": False
        }
        print(f"  - å‰ªæé…ç½®: {prune_config}")
        
        # æ¨¡æ‹Ÿå‹ç¼©æ•ˆæœ
        original_size = 100.0  # MB
        quantized_size = original_size * 0.5  # é‡åŒ–åå¤§å°
        pruned_size = quantized_size * 0.7    # å‰ªæåå¤§å°
        
        compression_ratio = original_size / pruned_size
        
        print(f"âœ… å‹ç¼©å®Œæˆ")
        print(f"  - åŸå§‹æ¨¡å‹å¤§å°: {original_size:.1f} MB")
        print(f"  - å‹ç¼©åå¤§å°: {pruned_size:.1f} MB")
        print(f"  - å‹ç¼©æ¯”: {compression_ratio:.1f}x")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹å‹ç¼©å¤±è´¥: {e}")
        return False

def demo_hyperparameter_optimization():
    """æ¼”ç¤ºè¶…å‚æ•°ä¼˜åŒ–"""
    print("\nâš¡ 5. è¶…å‚æ•°ä¼˜åŒ–æ¼”ç¤º")
    print("-" * 40)
    
    try:
        from eit_p.optimization import BayesianOptimizer, GridSearchOptimizer
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        bayesian_opt = BayesianOptimizer()
        grid_opt = GridSearchOptimizer()
        
        print("âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        # å®šä¹‰æœç´¢ç©ºé—´
        search_space = {
            "learning_rate": [0.001, 0.01, 0.1],
            "batch_size": [8, 16, 32],
            "hidden_dim": [64, 128, 256]
        }
        
        print(f"âœ… æœç´¢ç©ºé—´å®šä¹‰: {len(search_space)} ä¸ªå‚æ•°")
        
        # æ¨¡æ‹Ÿä¼˜åŒ–è¿‡ç¨‹
        print("\nğŸ” æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–...")
        
        best_score = 0
        best_params = None
        
        # æ¨¡æ‹Ÿç½‘æ ¼æœç´¢
        total_combinations = len(search_space["learning_rate"]) * len(search_space["batch_size"]) * len(search_space["hidden_dim"])
        print(f"  - æ€»ç»„åˆæ•°: {total_combinations}")
        
        for i, lr in enumerate(search_space["learning_rate"]):
            for j, bs in enumerate(search_space["batch_size"]):
                for k, hd in enumerate(search_space["hidden_dim"]):
                    # æ¨¡æ‹Ÿè¯„ä¼°åˆ†æ•°
                    score = np.random.uniform(0.7, 0.95)
                    
                    if score > best_score:
                        best_score = score
                        best_params = {"learning_rate": lr, "batch_size": bs, "hidden_dim": hd}
                    
                    print(f"  ç»„åˆ {i*9 + j*3 + k + 1}/{total_combinations}: "
                          f"lr={lr}, bs={bs}, hd={hd} -> score={score:.3f}")
        
        print(f"âœ… ä¼˜åŒ–å®Œæˆ")
        print(f"  - æœ€ä½³åˆ†æ•°: {best_score:.3f}")
        print(f"  - æœ€ä½³å‚æ•°: {best_params}")
        
        return best_params
        
    except Exception as e:
        print(f"âŒ è¶…å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    print("\nğŸ¯ å¼€å§‹EIT-På®Œæ•´è®­ç»ƒæ¼”ç¤º...")
    
    # åˆ›å»ºæ¼”ç¤ºæ•°æ®
    texts, labels = create_demo_data()
    
    # è¿è¡Œå„ä¸ªæ¼”ç¤º
    experiment_id = demo_training_process()
    ab_experiment_id = demo_ab_testing()
    compression_success = demo_model_compression()
    best_params = demo_hyperparameter_optimization()
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ‰ EIT-P å®Œæ•´è®­ç»ƒæ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)
    print("âœ¨ æ¼”ç¤ºç»“æœæ€»ç»“ï¼š")
    print(f"  â€¢ è®­ç»ƒå®éªŒ: {'âœ… æˆåŠŸ' if experiment_id else 'âŒ å¤±è´¥'}")
    print(f"  â€¢ A/Bæµ‹è¯•: {'âœ… æˆåŠŸ' if ab_experiment_id else 'âŒ å¤±è´¥'}")
    print(f"  â€¢ æ¨¡å‹å‹ç¼©: {'âœ… æˆåŠŸ' if compression_success else 'âŒ å¤±è´¥'}")
    print(f"  â€¢ è¶…å‚æ•°ä¼˜åŒ–: {'âœ… æˆåŠŸ' if best_params else 'âŒ å¤±è´¥'}")
    print("=" * 80)
    print("ğŸš€ EIT-Pæ¡†æ¶å·²å®Œå…¨éªŒè¯ï¼Œå¯ä»¥æŠ•å…¥ç”Ÿäº§ä½¿ç”¨ï¼")
    print("=" * 80)

if __name__ == "__main__":
    main()
