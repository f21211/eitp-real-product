#!/usr/bin/env python3
"""
Enhanced CEP-EIT-P Advanced Features Manager
é«˜çº§åŠŸèƒ½ç®¡ç†å™¨ - æ•´åˆæ‰€æœ‰é«˜çº§åŠŸèƒ½
"""

import sys
import os
sys.path.append('/mnt/sda1/myproject/datainall/AGI')

import torch
import logging
from datetime import datetime
from typing import Dict, List, Optional
from model_version_manager import ModelVersionManager
from ab_test_manager import ABTestManager
from distributed_training import run_distributed_training

class AdvancedFeaturesManager:
    """é«˜çº§åŠŸèƒ½ç®¡ç†å™¨"""
    
    def __init__(self):
        self.version_manager = ModelVersionManager()
        self.ab_test_manager = ABTestManager(self.version_manager)
        self.setup_logging()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger("AdvancedFeaturesManager")
    
    def run_distributed_training(self, world_size: int = 2, 
                                epochs: int = 100) -> Dict:
        """è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ"""
        self.logger.info(f"å¼€å§‹åˆ†å¸ƒå¼è®­ç»ƒ (World Size: {world_size})")
        
        # è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
        results = run_distributed_training(world_size, epochs)
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        if 'final_loss' in results:
            from eit_p_enhanced_cep import EnhancedCEPEITP, CEPParameters
            
            model = EnhancedCEPEITP(
                input_dim=784,
                hidden_dims=[512, 256, 128],
                output_dim=10,
                cep_params=CEPParameters()
            )
            
            performance_metrics = {
                'final_loss': results['final_loss'],
                'consciousness_level': results['final_consciousness_level'],
                'training_time': results['training_time']
            }
            
            version = self.version_manager.create_version(
                model, performance_metrics, 
                description=f"åˆ†å¸ƒå¼è®­ç»ƒç»“æœ (World Size: {world_size})",
                tags=['distributed', 'training']
            )
            
            self.logger.info(f"åˆ†å¸ƒå¼è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ç‰ˆæœ¬: {version}")
            results['model_version'] = version
        
        return results
    
    def create_ab_test(self, model_a_version: str, model_b_version: str,
                      traffic_split: float = 0.5) -> str:
        """åˆ›å»ºA/Bæµ‹è¯•"""
        test_id = f"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        return self.ab_test_manager.create_test(
            test_id=test_id,
            model_a_version=model_a_version,
            model_b_version=model_b_version,
            traffic_split=traffic_split
        )
    
    def get_model_for_inference(self, test_id: str, user_id: str) -> str:
        """ä¸ºæ¨ç†è·å–æ¨¡å‹ç‰ˆæœ¬"""
        return self.ab_test_manager.get_model_for_request(test_id, user_id)
    
    def record_inference_result(self, test_id: str, user_id: str, 
                               model_version: str, metrics: Dict):
        """è®°å½•æ¨ç†ç»“æœ"""
        self.ab_test_manager.record_test_result(test_id, user_id, model_version, metrics)
    
    def get_test_analysis(self, test_id: str) -> Dict:
        """è·å–æµ‹è¯•åˆ†æ"""
        return self.ab_test_manager.get_test_results(test_id)
    
    def list_model_versions(self) -> List[Dict]:
        """åˆ—å‡ºç°æœ‰æ¨¡å‹ç‰ˆæœ¬"""
        return self.version_manager.list_versions()
    
    def get_latest_model_version(self) -> Optional[str]:
        """è·å–æœ€æ–°æ¨¡å‹ç‰ˆæœ¬"""
        return self.version_manager.get_latest_version()
    
    def load_model_version(self, version: str):
        """åŠ è½½æŒ‡å®šç‰ˆæœ¬çš„æ¨¡å‹"""
        return self.version_manager.load_model(version)
    
    def list_ab_tests(self) -> List[Dict]:
        """åˆ—å‡ºç°æœ‰A/Bæµ‹è¯•"""
        return self.ab_test_manager.list_tests()
    
    def stop_ab_test(self, test_id: str):
        """åœæ­¢A/Bæµ‹è¯•"""
        self.ab_test_manager.stop_test(test_id)
    
    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            'model_versions': len(self.version_manager.versions),
            'active_tests': len([t for t in self.ab_test_manager.tests.values() 
                                if t.status == 'active']),
            'total_tests': len(self.ab_test_manager.tests),
            'latest_version': self.version_manager.get_latest_version(),
            'timestamp': datetime.now().isoformat()
        }
    
    def create_model_comparison(self, versions: List[str]) -> Dict:
        """åˆ›å»ºæ¨¡å‹å¯¹æ¯”åˆ†æ"""
        comparison = {
            'versions': versions,
            'comparison_data': {},
            'timestamp': datetime.now().isoformat()
        }
        
        for version in versions:
            try:
                model, metrics = self.version_manager.load_model(version)
                comparison['comparison_data'][version] = {
                    'performance_metrics': metrics,
                    'cep_params': self.version_manager.get_version_info(version)['cep_params']
                }
            except Exception as e:
                self.logger.error(f"åŠ è½½ç‰ˆæœ¬ {version} å¤±è´¥: {e}")
                comparison['comparison_data'][version] = {'error': str(e)}
        
        return comparison
    
    def export_model_version(self, version: str, export_path: str) -> bool:
        """å¯¼å‡ºæ¨¡å‹ç‰ˆæœ¬"""
        try:
            model, metrics = self.version_manager.load_model(version)
            
            export_data = {
                'version': version,
                'model_state_dict': model.state_dict(),
                'cep_params': model.cep_params.__dict__,
                'performance_metrics': metrics,
                'architecture': {
                    'input_dim': model.input_dim,
                    'hidden_dims': model.hidden_dims,
                    'output_dim': model.output_dim
                },
                'export_timestamp': datetime.now().isoformat()
            }
            
            torch.save(export_data, export_path)
            self.logger.info(f"æ¨¡å‹ç‰ˆæœ¬ {version} å·²å¯¼å‡ºåˆ° {export_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºæ¨¡å‹ç‰ˆæœ¬ {version} å¤±è´¥: {e}")
            return False
    
    def import_model_version(self, import_path: str, description: str = "") -> Optional[str]:
        """å¯¼å…¥æ¨¡å‹ç‰ˆæœ¬"""
        try:
            import_data = torch.load(import_path, map_location='cpu')
            
            from eit_p_enhanced_cep import EnhancedCEPEITP, CEPParameters
            
            # åˆ›å»ºæ¨¡å‹
            cep_params = CEPParameters(**import_data['cep_params'])
            model = EnhancedCEPEITP(
                input_dim=import_data['architecture']['input_dim'],
                hidden_dims=import_data['architecture']['hidden_dims'],
                output_dim=import_data['architecture']['output_dim'],
                cep_params=cep_params
            )
            
            # åŠ è½½æƒé‡
            model.load_state_dict(import_data['model_state_dict'])
            
            # åˆ›å»ºç‰ˆæœ¬
            version = self.version_manager.create_version(
                model,
                import_data['performance_metrics'],
                description=description or f"å¯¼å…¥çš„æ¨¡å‹ç‰ˆæœ¬",
                tags=['imported']
            )
            
            self.logger.info(f"æ¨¡å‹ç‰ˆæœ¬å·²å¯¼å…¥: {version}")
            return version
            
        except Exception as e:
            self.logger.error(f"å¯¼å…¥æ¨¡å‹ç‰ˆæœ¬å¤±è´¥: {e}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Enhanced CEP-EIT-P Advanced Features Manager")
    print("=" * 60)
    
    # åˆ›å»ºé«˜çº§åŠŸèƒ½ç®¡ç†å™¨
    manager = AdvancedFeaturesManager()
    
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    status = manager.get_system_status()
    print(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€:")
    print(f"  æ¨¡å‹ç‰ˆæœ¬: {status['model_versions']}")
    print(f"  æ´»è·ƒæµ‹è¯•: {status['active_tests']}")
    print(f"  æ€»æµ‹è¯•æ•°: {status['total_tests']}")
    print(f"  æœ€æ–°ç‰ˆæœ¬: {status['latest_version']}")
    
    # åˆ›å»ºæµ‹è¯•æ¨¡å‹ç‰ˆæœ¬
    from eit_p_enhanced_cep import EnhancedCEPEITP, CEPParameters
    
    model = EnhancedCEPEITP(
        input_dim=784,
        hidden_dims=[512, 256, 128],
        output_dim=10,
        cep_params=CEPParameters()
    )
    
    # åˆ›å»ºç‰ˆæœ¬
    version = manager.version_manager.create_version(
        model,
        {'consciousness_level': 2, 'accuracy': 0.9, 'inference_time': 0.001},
        "æµ‹è¯•æ¨¡å‹ç‰ˆæœ¬",
        ['test', 'demo']
    )
    
    print(f"âœ… åˆ›å»ºæ¨¡å‹ç‰ˆæœ¬: {version}")
    
    # åˆ›å»ºA/Bæµ‹è¯•
    test_id = manager.create_ab_test(version, version, 0.5)
    print(f"âœ… åˆ›å»ºA/Bæµ‹è¯•: {test_id}")
    
    # æ¨¡æ‹Ÿæµ‹è¯•
    for i in range(5):
        user_id = f"user_{i}"
        model_version = manager.get_model_for_inference(test_id, user_id)
        metrics = {'consciousness_level': 2, 'inference_time': 0.001, 'accuracy': 0.9}
        manager.record_inference_result(test_id, user_id, model_version, metrics)
    
    # è·å–æµ‹è¯•åˆ†æ
    analysis = manager.get_test_analysis(test_id)
    print(f"ğŸ“Š æµ‹è¯•åˆ†æ: {analysis['total_requests']} ä¸ªè¯·æ±‚")
    
    print("ğŸ‰ é«˜çº§åŠŸèƒ½ç®¡ç†å™¨æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()
