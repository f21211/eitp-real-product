#!/usr/bin/env python3
"""
Enhanced CEP-EIT-P Production Monitor
ç”Ÿäº§ç¯å¢ƒç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ
"""

import sys
import os
sys.path.append('/mnt/sda1/myproject/datainall/AGI')

import time
import json
import psutil
import requests
import threading
import logging
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Callable
import matplotlib.pyplot as plt
import numpy as np
from collections import deque

@dataclass
class SystemMetrics:
    """ç³»ç»ŸæŒ‡æ ‡"""
    timestamp: str
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    memory_available_mb: float
    disk_usage_percent: float
    disk_free_gb: float
    network_sent_mb: float
    network_recv_mb: float
    load_average: List[float]

@dataclass
class APIMetrics:
    """APIæŒ‡æ ‡"""
    timestamp: str
    endpoint: str
    response_time: float
    status_code: int
    success: bool
    error_message: Optional[str] = None

@dataclass
class ModelMetrics:
    """æ¨¡å‹æŒ‡æ ‡"""
    timestamp: str
    consciousness_level: int
    constraint_satisfaction: float
    fractal_dimension: float
    complexity_coefficient: float
    inference_time: float
    memory_usage_mb: float

@dataclass
class Alert:
    """å‘Šè­¦"""
    timestamp: str
    level: str  # INFO, WARNING, ERROR, CRITICAL
    category: str  # SYSTEM, API, MODEL, PERFORMANCE
    message: str
    details: Dict
    resolved: bool = False

class ProductionMonitor:
    """ç”Ÿäº§ç¯å¢ƒç›‘æ§å™¨"""
    
    def __init__(self, api_base_url: str = "http://localhost:5000", 
                 check_interval: int = 30, alert_thresholds: Dict = None):
        self.api_base_url = api_base_url
        self.check_interval = check_interval
        self.running = False
        self.monitor_thread = None
        
        # é»˜è®¤å‘Šè­¦é˜ˆå€¼
        self.alert_thresholds = alert_thresholds or {
            'cpu_percent': 80.0,
            'memory_percent': 85.0,
            'disk_usage_percent': 90.0,
            'response_time': 5.0,
            'error_rate': 0.1,
            'consciousness_level': 1,
            'constraint_satisfaction': 0.3
        }
        
        # æ•°æ®å­˜å‚¨
        self.system_metrics_history = deque(maxlen=1000)
        self.api_metrics_history = deque(maxlen=1000)
        self.model_metrics_history = deque(maxlen=1000)
        self.alerts = []
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # å‘Šè­¦å›è°ƒ
        self.alert_callbacks = []
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('production_monitor.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def add_alert_callback(self, callback: Callable[[Alert], None]):
        """æ·»åŠ å‘Šè­¦å›è°ƒå‡½æ•°"""
        self.alert_callbacks.append(callback)
    
    def collect_system_metrics(self) -> SystemMetrics:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        try:
            # CPUå’Œå†…å­˜
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            # ç£ç›˜ä½¿ç”¨
            disk = psutil.disk_usage('/')
            
            # ç½‘ç»œç»Ÿè®¡
            network = psutil.net_io_counters()
            
            # è´Ÿè½½å¹³å‡å€¼
            load_avg = psutil.getloadavg() if hasattr(psutil, 'getloadavg') else [0, 0, 0]
            
            metrics = SystemMetrics(
                timestamp=datetime.now().isoformat(),
                cpu_percent=cpu_percent,
                memory_percent=memory.percent,
                memory_used_mb=memory.used / (1024 * 1024),
                memory_available_mb=memory.available / (1024 * 1024),
                disk_usage_percent=disk.percent,
                disk_free_gb=disk.free / (1024 * 1024 * 1024),
                network_sent_mb=network.bytes_sent / (1024 * 1024),
                network_recv_mb=network.bytes_recv / (1024 * 1024),
                load_average=list(load_avg)
            )
            
            self.system_metrics_history.append(metrics)
            return metrics
            
        except Exception as e:
            self.logger.error(f"æ”¶é›†ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
            return None
    
    def collect_api_metrics(self) -> List[APIMetrics]:
        """æ”¶é›†APIæŒ‡æ ‡"""
        api_metrics = []
        endpoints = [
            '/api/health',
            '/api/model_info',
            '/api/consciousness',
            '/api/performance'
        ]
        
        for endpoint in endpoints:
            try:
                start_time = time.time()
                response = requests.get(f"{self.api_base_url}{endpoint}", timeout=10)
                response_time = time.time() - start_time
                
                metric = APIMetrics(
                    timestamp=datetime.now().isoformat(),
                    endpoint=endpoint,
                    response_time=response_time,
                    status_code=response.status_code,
                    success=response.status_code == 200,
                    error_message=None if response.status_code == 200 else f"HTTP {response.status_code}"
                )
                
                api_metrics.append(metric)
                self.api_metrics_history.append(metric)
                
            except Exception as e:
                metric = APIMetrics(
                    timestamp=datetime.now().isoformat(),
                    endpoint=endpoint,
                    response_time=0.0,
                    status_code=0,
                    success=False,
                    error_message=str(e)
                )
                
                api_metrics.append(metric)
                self.api_metrics_history.append(metric)
        
        return api_metrics
    
    def collect_model_metrics(self) -> Optional[ModelMetrics]:
        """æ”¶é›†æ¨¡å‹æŒ‡æ ‡"""
        try:
            # æµ‹è¯•æ¨ç†
            test_input = [0.1] * 784
            start_time = time.time()
            
            response = requests.post(
                f"{self.api_base_url}/api/inference",
                json={'input': test_input},
                timeout=10
            )
            
            inference_time = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                consciousness_metrics = data['consciousness_metrics']
                
                # è·å–å†…å­˜ä½¿ç”¨
                process = psutil.Process()
                memory_usage = process.memory_info().rss / (1024 * 1024)
                
                metric = ModelMetrics(
                    timestamp=datetime.now().isoformat(),
                    consciousness_level=consciousness_metrics['level'],
                    constraint_satisfaction=consciousness_metrics.get('constraint_satisfaction', 0.0),
                    fractal_dimension=consciousness_metrics['fractal_dimension'],
                    complexity_coefficient=consciousness_metrics['complexity_coefficient'],
                    inference_time=inference_time,
                    memory_usage_mb=memory_usage
                )
                
                self.model_metrics_history.append(metric)
                return metric
            else:
                self.logger.warning(f"æ¨¡å‹æ¨ç†å¤±è´¥: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.error(f"æ”¶é›†æ¨¡å‹æŒ‡æ ‡å¤±è´¥: {e}")
            return None
    
    def check_alerts(self, system_metrics: SystemMetrics, 
                    api_metrics: List[APIMetrics], 
                    model_metrics: Optional[ModelMetrics]):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        current_time = datetime.now().isoformat()
        
        # ç³»ç»Ÿå‘Šè­¦
        if system_metrics:
            if system_metrics.cpu_percent > self.alert_thresholds['cpu_percent']:
                self.create_alert(
                    level="WARNING",
                    category="SYSTEM",
                    message=f"CPUä½¿ç”¨ç‡è¿‡é«˜: {system_metrics.cpu_percent:.1f}%",
                    details={'cpu_percent': system_metrics.cpu_percent}
                )
            
            if system_metrics.memory_percent > self.alert_thresholds['memory_percent']:
                self.create_alert(
                    level="WARNING",
                    category="SYSTEM",
                    message=f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {system_metrics.memory_percent:.1f}%",
                    details={'memory_percent': system_metrics.memory_percent}
                )
            
            if system_metrics.disk_usage_percent > self.alert_thresholds['disk_usage_percent']:
                self.create_alert(
                    level="ERROR",
                    category="SYSTEM",
                    message=f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {system_metrics.disk_usage_percent:.1f}%",
                    details={'disk_usage_percent': system_metrics.disk_usage_percent}
                )
        
        # APIå‘Šè­¦
        if api_metrics:
            failed_requests = [m for m in api_metrics if not m.success]
            if failed_requests:
                error_rate = len(failed_requests) / len(api_metrics)
                if error_rate > self.alert_thresholds['error_rate']:
                    self.create_alert(
                        level="ERROR",
                        category="API",
                        message=f"APIé”™è¯¯ç‡è¿‡é«˜: {error_rate:.1%}",
                        details={'error_rate': error_rate, 'failed_requests': len(failed_requests)}
                    )
            
            avg_response_time = np.mean([m.response_time for m in api_metrics])
            if avg_response_time > self.alert_thresholds['response_time']:
                self.create_alert(
                    level="WARNING",
                    category="API",
                    message=f"APIå“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.2f}s",
                    details={'avg_response_time': avg_response_time}
                )
        
        # æ¨¡å‹å‘Šè­¦
        if model_metrics:
            if model_metrics.consciousness_level < self.alert_thresholds['consciousness_level']:
                self.create_alert(
                    level="WARNING",
                    category="MODEL",
                    message=f"æ„è¯†æ°´å¹³è¿‡ä½: {model_metrics.consciousness_level}/4",
                    details={'consciousness_level': model_metrics.consciousness_level}
                )
            
            if model_metrics.constraint_satisfaction < self.alert_thresholds['constraint_satisfaction']:
                self.create_alert(
                    level="WARNING",
                    category="MODEL",
                    message=f"çº¦æŸæ»¡è¶³ç‡è¿‡ä½: {model_metrics.constraint_satisfaction:.1%}",
                    details={'constraint_satisfaction': model_metrics.constraint_satisfaction}
                )
    
    def create_alert(self, level: str, category: str, message: str, details: Dict):
        """åˆ›å»ºå‘Šè­¦"""
        alert = Alert(
            timestamp=datetime.now().isoformat(),
            level=level,
            category=category,
            message=message,
            details=details
        )
        
        self.alerts.append(alert)
        self.logger.warning(f"[{level}] {category}: {message}")
        
        # è°ƒç”¨å‘Šè­¦å›è°ƒ
        for callback in self.alert_callbacks:
            try:
                callback(alert)
            except Exception as e:
                self.logger.error(f"å‘Šè­¦å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
    
    def monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        self.logger.info("å¼€å§‹ç”Ÿäº§ç¯å¢ƒç›‘æ§...")
        
        while self.running:
            try:
                # æ”¶é›†æŒ‡æ ‡
                system_metrics = self.collect_system_metrics()
                api_metrics = self.collect_api_metrics()
                model_metrics = self.collect_model_metrics()
                
                # æ£€æŸ¥å‘Šè­¦
                self.check_alerts(system_metrics, api_metrics, model_metrics)
                
                # æ‰“å°çŠ¶æ€
                if system_metrics:
                    self.logger.info(
                        f"ç³»ç»ŸçŠ¶æ€ - CPU: {system_metrics.cpu_percent:.1f}%, "
                        f"å†…å­˜: {system_metrics.memory_percent:.1f}%, "
                        f"ç£ç›˜: {system_metrics.disk_usage_percent:.1f}%"
                    )
                
                if model_metrics:
                    self.logger.info(
                        f"æ¨¡å‹çŠ¶æ€ - æ„è¯†æ°´å¹³: {model_metrics.consciousness_level}/4, "
                        f"æ¨ç†æ—¶é—´: {model_metrics.inference_time:.3f}s"
                    )
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(self.check_interval)
                
            except Exception as e:
                self.logger.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                time.sleep(self.check_interval)
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.running:
            self.logger.warning("ç›‘æ§å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.running = True
        self.monitor_thread = threading.Thread(target=self.monitor_loop, daemon=True)
        self.monitor_thread.start()
        self.logger.info("ç”Ÿäº§ç¯å¢ƒç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        self.logger.info("ç”Ÿäº§ç¯å¢ƒç›‘æ§å·²åœæ­¢")
    
    def get_status_report(self) -> Dict:
        """è·å–çŠ¶æ€æŠ¥å‘Š"""
        current_time = datetime.now()
        
        # æœ€è¿‘1å°æ—¶çš„æŒ‡æ ‡
        recent_time = current_time - timedelta(hours=1)
        recent_system = [m for m in self.system_metrics_history 
                        if datetime.fromisoformat(m.timestamp) > recent_time]
        recent_api = [m for m in self.api_metrics_history 
                     if datetime.fromisoformat(m.timestamp) > recent_time]
        recent_model = [m for m in self.model_metrics_history 
                       if datetime.fromisoformat(m.timestamp) > recent_time]
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        report = {
            'timestamp': current_time.isoformat(),
            'monitoring_status': 'running' if self.running else 'stopped',
            'system_metrics': {
                'total_samples': len(self.system_metrics_history),
                'recent_samples': len(recent_system),
                'avg_cpu_percent': np.mean([m.cpu_percent for m in recent_system]) if recent_system else 0,
                'avg_memory_percent': np.mean([m.memory_percent for m in recent_system]) if recent_system else 0,
                'avg_disk_usage_percent': np.mean([m.disk_usage_percent for m in recent_system]) if recent_system else 0
            },
            'api_metrics': {
                'total_samples': len(self.api_metrics_history),
                'recent_samples': len(recent_api),
                'success_rate': len([m for m in recent_api if m.success]) / len(recent_api) if recent_api else 0,
                'avg_response_time': np.mean([m.response_time for m in recent_api]) if recent_api else 0
            },
            'model_metrics': {
                'total_samples': len(self.model_metrics_history),
                'recent_samples': len(recent_model),
                'avg_consciousness_level': np.mean([m.consciousness_level for m in recent_model]) if recent_model else 0,
                'avg_inference_time': np.mean([m.inference_time for m in recent_model]) if recent_model else 0
            },
            'alerts': {
                'total_alerts': len(self.alerts),
                'recent_alerts': len([a for a in self.alerts 
                                    if datetime.fromisoformat(a.timestamp) > recent_time]),
                'unresolved_alerts': len([a for a in self.alerts if not a.resolved]),
                'alert_levels': {
                    'INFO': len([a for a in self.alerts if a.level == 'INFO']),
                    'WARNING': len([a for a in self.alerts if a.level == 'WARNING']),
                    'ERROR': len([a for a in self.alerts if a.level == 'ERROR']),
                    'CRITICAL': len([a for a in self.alerts if a.level == 'CRITICAL'])
                }
            }
        }
        
        return report
    
    def save_metrics_to_file(self, filename: str = None):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        if filename is None:
            filename = f"production_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        data = {
            'system_metrics': [asdict(m) for m in self.system_metrics_history],
            'api_metrics': [asdict(m) for m in self.api_metrics_history],
            'model_metrics': [asdict(m) for m in self.model_metrics_history],
            'alerts': [asdict(a) for a in self.alerts]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"æŒ‡æ ‡æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
        return filename
    
    def create_dashboard_visualization(self, save_path: str = "production_dashboard.png"):
        """åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿å¯è§†åŒ–"""
        if not self.system_metrics_history:
            self.logger.warning("æ²¡æœ‰è¶³å¤Ÿçš„æŒ‡æ ‡æ•°æ®åˆ›å»ºå¯è§†åŒ–")
            return
        
        # å‡†å¤‡æ•°æ®
        timestamps = [datetime.fromisoformat(m.timestamp) for m in self.system_metrics_history]
        cpu_data = [m.cpu_percent for m in self.system_metrics_history]
        memory_data = [m.memory_percent for m in self.system_metrics_history]
        disk_data = [m.disk_usage_percent for m in self.system_metrics_history]
        
        # åˆ›å»ºå›¾è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # CPUä½¿ç”¨ç‡
        ax1.plot(timestamps, cpu_data, 'b-', linewidth=2, label='CPUä½¿ç”¨ç‡')
        ax1.axhline(y=self.alert_thresholds['cpu_percent'], color='r', linestyle='--', alpha=0.7, label='å‘Šè­¦é˜ˆå€¼')
        ax1.set_title('CPUä½¿ç”¨ç‡ç›‘æ§', fontsize=14, fontweight='bold')
        ax1.set_ylabel('CPUä½¿ç”¨ç‡ (%)')
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        
        # å†…å­˜ä½¿ç”¨ç‡
        ax2.plot(timestamps, memory_data, 'g-', linewidth=2, label='å†…å­˜ä½¿ç”¨ç‡')
        ax2.axhline(y=self.alert_thresholds['memory_percent'], color='r', linestyle='--', alpha=0.7, label='å‘Šè­¦é˜ˆå€¼')
        ax2.set_title('å†…å­˜ä½¿ç”¨ç‡ç›‘æ§', fontsize=14, fontweight='bold')
        ax2.set_ylabel('å†…å­˜ä½¿ç”¨ç‡ (%)')
        ax2.grid(True, alpha=0.3)
        ax2.legend()
        
        # ç£ç›˜ä½¿ç”¨ç‡
        ax3.plot(timestamps, disk_data, 'm-', linewidth=2, label='ç£ç›˜ä½¿ç”¨ç‡')
        ax3.axhline(y=self.alert_thresholds['disk_usage_percent'], color='r', linestyle='--', alpha=0.7, label='å‘Šè­¦é˜ˆå€¼')
        ax3.set_title('ç£ç›˜ä½¿ç”¨ç‡ç›‘æ§', fontsize=14, fontweight='bold')
        ax3.set_ylabel('ç£ç›˜ä½¿ç”¨ç‡ (%)')
        ax3.grid(True, alpha=0.3)
        ax3.legend()
        
        # å‘Šè­¦ç»Ÿè®¡
        alert_levels = ['INFO', 'WARNING', 'ERROR', 'CRITICAL']
        alert_counts = [len([a for a in self.alerts if a.level == level]) for level in alert_levels]
        colors = ['blue', 'orange', 'red', 'darkred']
        
        ax4.bar(alert_levels, alert_counts, color=colors, alpha=0.7)
        ax4.set_title('å‘Šè­¦ç»Ÿè®¡', fontsize=14, fontweight='bold')
        ax4.set_ylabel('å‘Šè­¦æ•°é‡')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"ç›‘æ§ä»ªè¡¨æ¿å·²ä¿å­˜åˆ°: {save_path}")

def alert_email_callback(alert: Alert):
    """é‚®ä»¶å‘Šè­¦å›è°ƒç¤ºä¾‹"""
    print(f"ğŸ“§ é‚®ä»¶å‘Šè­¦: [{alert.level}] {alert.category} - {alert.message}")

def alert_slack_callback(alert: Alert):
    """Slackå‘Šè­¦å›è°ƒç¤ºä¾‹"""
    print(f"ğŸ’¬ Slackå‘Šè­¦: [{alert.level}] {alert.category} - {alert.message}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Enhanced CEP-EIT-P Production Monitor")
    print("=" * 50)
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = ProductionMonitor(
        api_base_url="http://localhost:5000",
        check_interval=30
    )
    
    # æ·»åŠ å‘Šè­¦å›è°ƒ
    monitor.add_alert_callback(alert_email_callback)
    monitor.add_alert_callback(alert_slack_callback)
    
    try:
        # å¼€å§‹ç›‘æ§
        monitor.start_monitoring()
        
        # è¿è¡Œä¸€æ®µæ—¶é—´
        print("ğŸš€ ç›‘æ§å·²å¯åŠ¨ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")
        
        while True:
            time.sleep(60)  # æ¯åˆ†é’Ÿæ‰“å°ä¸€æ¬¡çŠ¶æ€æŠ¥å‘Š
            
            # æ‰“å°çŠ¶æ€æŠ¥å‘Š
            report = monitor.get_status_report()
            print(f"\nğŸ“Š çŠ¶æ€æŠ¥å‘Š - {report['timestamp']}")
            print(f"ç³»ç»Ÿ: CPU {report['system_metrics']['avg_cpu_percent']:.1f}%, "
                  f"å†…å­˜ {report['system_metrics']['avg_memory_percent']:.1f}%")
            print(f"API: æˆåŠŸç‡ {report['api_metrics']['success_rate']:.1%}, "
                  f"å“åº”æ—¶é—´ {report['api_metrics']['avg_response_time']:.3f}s")
            print(f"æ¨¡å‹: æ„è¯†æ°´å¹³ {report['model_metrics']['avg_consciousness_level']:.1f}, "
                  f"æ¨ç†æ—¶é—´ {report['model_metrics']['avg_inference_time']:.3f}s")
            print(f"å‘Šè­¦: æ€»è®¡ {report['alerts']['total_alerts']}, "
                  f"æœªè§£å†³ {report['alerts']['unresolved_alerts']}")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ åœæ­¢ç›‘æ§...")
        monitor.stop_monitoring()
        
        # ä¿å­˜æŒ‡æ ‡æ•°æ®
        filename = monitor.save_metrics_to_file()
        
        # åˆ›å»ºå¯è§†åŒ–
        monitor.create_dashboard_visualization()
        
        print(f"ğŸ“ æŒ‡æ ‡æ•°æ®å·²ä¿å­˜: {filename}")
        print("ğŸ“Š ç›‘æ§ä»ªè¡¨æ¿å·²ç”Ÿæˆ: production_dashboard.png")
        print("ğŸ‰ ç›‘æ§å·²åœæ­¢")

if __name__ == "__main__":
    main()
