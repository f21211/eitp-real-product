#!/usr/bin/env python3
"""
Enhanced CEP-EIT-P Distributed Training
åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å—
"""

import sys
import os
sys.path.append('/mnt/sda1/myproject/datainall/AGI')

import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
import numpy as np
import time
import logging
from typing import Dict, List
from eit_p_enhanced_cep import EnhancedCEPEITP, CEPParameters

class DistributedTrainer:
    """åˆ†å¸ƒå¼è®­ç»ƒå™¨"""
    
    def __init__(self, world_size: int = 1, rank: int = 0):
        self.world_size = world_size
        self.rank = rank
        self.device = torch.device(f"cuda:{rank}" if torch.cuda.is_available() else "cpu")
        self.setup_logging()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(f"DistributedTrainer-{self.rank}")
    
    def setup_distributed(self):
        """è®¾ç½®åˆ†å¸ƒå¼ç¯å¢ƒ"""
        if self.world_size > 1:
            dist.init_process_group(
                backend="nccl" if torch.cuda.is_available() else "gloo",
                init_method="env://",
                world_size=self.world_size,
                rank=self.rank
            )
            torch.cuda.set_device(self.rank)
    
    def train_distributed(self, model: EnhancedCEPEITP, 
                         train_data: torch.Tensor, 
                         epochs: int = 100,
                         learning_rate: float = 0.001) -> Dict:
        """åˆ†å¸ƒå¼è®­ç»ƒ"""
        self.logger.info(f"å¼€å§‹åˆ†å¸ƒå¼è®­ç»ƒ (Rank {self.rank}/{self.world_size})")
        
        # è®¾ç½®åˆ†å¸ƒå¼
        if self.world_size > 1:
            self.setup_distributed()
            model = model.to(self.device)
            model = DDP(model, device_ids=[self.rank])
        
        # ä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
        criterion = torch.nn.MSELoss()
        
        # è®­ç»ƒå¾ªç¯
        training_history = []
        start_time = time.time()
        
        for epoch in range(epochs):
            model.train()
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            output, metrics = model(train_data)
            
            # è®¡ç®—æŸå¤±
            target = torch.randn_like(output)
            loss = criterion(output, target)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            # è®°å½•è®­ç»ƒå†å²
            epoch_time = time.time() - start_time
            training_history.append({
                'epoch': epoch,
                'loss': loss.item(),
                'consciousness_level': metrics['consciousness_metrics'].consciousness_level,
                'time': epoch_time
            })
            
            if epoch % 10 == 0:
                self.logger.info(f"Epoch {epoch}: Loss={loss.item():.6f}, "
                               f"Consciousness={metrics['consciousness_metrics'].consciousness_level}/4")
        
        training_time = time.time() - start_time
        
        # æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒ
        if self.world_size > 1:
            dist.destroy_process_group()
        
        return {
            'training_time': training_time,
            'final_loss': loss.item(),
            'final_consciousness_level': metrics['consciousness_metrics'].consciousness_level,
            'training_history': training_history
        }

def run_distributed_training(world_size: int = 2, epochs: int = 100) -> Dict:
    """è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ"""
    print(f"ğŸš€ å¼€å§‹åˆ†å¸ƒå¼è®­ç»ƒ (World Size: {world_size})")
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®
    train_data = torch.randn(1000, 784)
    
    if world_size > 1:
        # å¤šè¿›ç¨‹åˆ†å¸ƒå¼è®­ç»ƒ
        mp.spawn(_train_worker, 
                args=(world_size, train_data, epochs),
                nprocs=world_size,
                join=True)
    else:
        # å•è¿›ç¨‹è®­ç»ƒ
        trainer = DistributedTrainer(world_size=1, rank=0)
        model = EnhancedCEPEITP(
            input_dim=784,
            hidden_dims=[512, 256, 128],
            output_dim=10,
            cep_params=CEPParameters()
        )
        return trainer.train_distributed(model, train_data, epochs)

def _train_worker(rank: int, world_size: int, 
                 train_data: torch.Tensor, epochs: int):
    """è®­ç»ƒå·¥ä½œè¿›ç¨‹"""
    trainer = DistributedTrainer(world_size=world_size, rank=rank)
    model = EnhancedCEPEITP(
        input_dim=784,
        hidden_dims=[512, 256, 128],
        output_dim=10,
        cep_params=CEPParameters()
    )
    
    results = trainer.train_distributed(model, train_data, epochs)
    
    if rank == 0:
        print(f"âœ… åˆ†å¸ƒå¼è®­ç»ƒå®Œæˆ: {results['training_time']:.2f}s")
        print(f"ğŸ“Š æœ€ç»ˆæŸå¤±: {results['final_loss']:.6f}")
        print(f"ğŸ§  æ„è¯†æ°´å¹³: {results['final_consciousness_level']}/4")

if __name__ == "__main__":
    # æµ‹è¯•åˆ†å¸ƒå¼è®­ç»ƒ
    results = run_distributed_training(world_size=1, epochs=50)
    print("ğŸ‰ åˆ†å¸ƒå¼è®­ç»ƒæµ‹è¯•å®Œæˆ!")
